---
title: "Bivalves_Analysis"
author: "Dan Bez Golanski"
date: "`r Sys.Date()`"
output: html_document
---

##Functions

```{r}
# The function takes datetime data that was saved as text in csv/xlsx file and convert it to POSIxlt, can handle combined data including both numeric and non numeric datetime
Convert_time_csv <- function(data, final_format, initial_format="ymd HMS",correct_time=T ) {
  temp_data<-data
  #for data saved as numeric in csv
  temp_data<-as.numeric(temp_data)
  temp_data<-as_datetime(as_date(temp_data, origin = "1899-12-30"), tz = Sys.timezone())
  #for data not saved as numeric in csv
  na_index<-which(is.na(temp_data))
  if(length(na_index)!=length(data))
  {
    for (i in na_index) {
      temp_data[i]<-parse_date_time(data[i],orders = initial_format,truncated = 3)
    }
  } else # if all data is character
  {
    temp_data<-parse_date_time(data,orders = initial_format,truncated = 3)
  }
  temp_data <- as.POSIXlt(temp_data)
  if(correct_time)
  {
    #correct time that rounded wrongly because it was numeric
    for (row_num in 1:length(temp_data)) {
    temptime<-unclass(temp_data[row_num])
    tempsec<-temptime$sec
    if (tempsec>58) {
      temp_data[row_num]<-temp_data[row_num]+1
      }
    }
  }
  temp_data<-strftime(temp_data,format = final_format)
  return(temp_data)
}

# This functions gets a bivalve df and returns it after calculate the different metrics for a given time interval
biv_df_cut_times <- function(biv_df,date_col_num,break_interval,date_format) {
  biv_df[,date_col_num] <- parse_date_time(biv_df[,date_col_num],orders = date_format)
  biv_df$group <- cut(biv_df[,date_col_num], breaks= break_interval)
  biv_df_cut_time <-biv_df %>%
  group_by(Deployment.number,Biv_num,group) %>%
  summarise(biv_open_interval_perc=mean(biv_open_percent),biv_open_interval=mean(biv_open),per99.9=mean(percentile.99))
  return(biv_df_cut_time)
}
```

##packages

```{r}
library(dplyr)
library(ggplot2)
library(lubridate)
library(openxlsx)
library(tidyr)
library(scales)
library(Hmisc) # for function rcorr
library(StreamMetabolism) #for getting sunrise and sunset
library(patchwork)

```

##load data

```{r}

db<-readRDS("Big_Hobo_database_raw.RDS")
db2wide<-read.csv("Big_Hobo_database_wide_2min_percent.csv")
dblong<-read.csv("Big_Hobo_databse_long_raw.csv")
dblong2<-read.csv("Big_Hobo_databse_long_2min_percent.csv")
dblong10<-read.csv("Big_Hobo_databse_long_10min_percent&env.csv")
dblong_hour <- read.csv("Big_Hobo_databse_long_hour_percent&env.csv")
```

##Change raw data to long format

```{r}
col_names<-c("Bivalve.4","Bivalve.6","Bivalve.7","Bivalve.8","Bivalve.0","Bivalve.12","Bivalve.21...","Bivalve.19","Bivavle.15","Bivavle.18","Bivavle.23","Bivavle.22")
dblong<-gather_(db,"Biv_num","biv_open",col_names,factor_key = T,na.rm = T)
dblong$Date...Time <- parse_date_time(dblong$Date...Time,orders = "dmy HMS",truncated = 3)
write.csv(dblong,"Big_Hobo_databse_long_raw.csv")
```

##Calculate opening percentages

```{r}
max_deploy<-max(dblong$Deployment.number)
for (dep_num in 1:max_deploy) {
  temp_array_deploy<-dblong[dblong$Deployment.number==dep_num,]
  biv_num<-unique(temp_array_deploy$Biv_num)
  for (biv_index in 1:length(biv_num)) {
    temp_array_bivnum <- temp_array_deploy %>%  filter(Biv_num==biv_num[biv_index])
    per99<-quantile(temp_array_bivnum$biv_open,0.999)
    dblong[dblong$Deployment.number==dep_num&dblong$Biv_num==biv_num[biv_index],5]<-per99
    names(dblong)[5]<-"percentile.99"
  }
}
rm(temp_array_bivnum,temp_array_deploy)
dblong$biv_open_percent<-dblong$biv_open/dblong$percentile.99*100
write.csv(dblong,"Big_Hobo_databse_long_raw_percent.csv")
```

##Average by different time intervals

```{r}
dblong2 <- biv_df_cut_times(dblong,1,"2 min","ymd HMS")
dblong10 <- biv_df_cut_times(dblong,1,"10 min","ymd HMS")
dblong_hour <- biv_df_cut_times(dblong,1,"1 hour","ymd HMS")
dblong_day <- biv_df_cut_times(dblong,1,"1 day","ymd HMS")
dblong_week <- biv_df_cut_times(dblong,1,"1 week","ymd HMS")
write.csv(dblong2, "Big_Hobo_databse_long_2min_percent.csv")
write.csv(dblong10, "Big_Hobo_databse_long_10min_percent.csv")
write.csv(dblong_hour, "Big_Hobo_databse_long_hour_percent.csv")
write.csv(dblong_week, "Big_Hobo_databse_long_week_percent.csv")

```

## Env_10min

```{r}
mx<-readRDS("BigMx.RDS")
obs<-readRDS("BigOBS.RDS")
#mx
names(mx)<-c("group","Temp","lux")
mx$group <- Convert_time_csv(mx$group,"%Y-%m-%d %H:%M:%S")
write.xlsx(mx,"BigMx.xlsx")
#merge to the bigHoboDatabase
dblong10<-merge(dblong10,mx,by="group",all.x = T)

#obs
names(obs)<-c("group","Turbidity")
obs$group <- Convert_time_csv(obs$group,"%Y-%m-%d %H:%M:%S")
write.xlsx(obs,"BigOBS.xlsx")
#merge to the bigHoboDatabase
dblong10<-merge(dblong10,obs,by="group",all.x = T)

#change NA to none
dblong10<-arrange(dblong10,Deployment.number,Biv_num,group)
dblong10 <- replace(dblong10, is.na(dblong10), "")
write.csv(dblong10, "Big_Hobo_databse_long_10min_percent&env.csv")
```

## Env_1hour and add obs and mx 1 hour average
```{r}
waves<-readRDS("Waves_data.RDS")
currents<-readRDS("Currents_data.RDS")
# waves
names(waves)[1]<-"group"
waves$group <- Convert_time_csv(waves$group,final_format = "%Y-%m-%d %H:%M:%S",initial_format = "dmy HMS",correct_time = F)
dblong_hour<-merge(dblong_hour,waves,by="group",all.x = T)
rm(waves)

#currents
#get only bottom currents
currents<-currents %>% filter(Depth..m.==23)
currents<-currents %>% select(-Depth..m.)
names(currents)[1]<-"group"
currents$group <- Convert_time_csv(currents$group,"%Y-%m-%d %H:%M:%S","dmy HM",correct_time = F)
dblong_hour<-merge(dblong_hour,currents,by="group",all.x = T)
rm(currents)

#change NA to none
names(dblong_hour)<-c("Date_time","Deployment.number","Bivalve.number","mean.biv.gap.precent","mean.biv.open.degree","percentile.99","Hs[m]","Tp[s]","Dp[deg]","H1/10[m]","Tmean[s]","Current.Speed[cm/sec]","Current.Direction[deg]")
dblong_hour<-arrange(dblong_hour,Deployment.number,Bivalve.number,Date_time)

#getting only environmental data and remove duplicates
env_10min_to_1hour <- dblong10 %>% 
  select(Temp,lux,Turbidity,group) %>% 
  distinct()
env_10min_to_1hour$group <- parse_date_time(env_10min_to_1hour$group,orders = "ymd HMS")
env_10min_to_1hour$Date_time <- cut(env_10min_to_1hour$group, breaks= "1 hour")
env_10min_to_1hour$Temp <- as.numeric(env_10min_to_1hour$Temp)
env_10min_to_1hour$lux <- as.numeric(env_10min_to_1hour$lux)
env_10min_to_1hour$Turbidity <- as.numeric(env_10min_to_1hour$Turbidity)
env_10min_to_1hour <-env_10min_to_1hour %>%
  group_by(Date_time) %>%
  summarise(Temp_1hour_mean=mean(Temp,na.rm=T),Lux_1hour_mean=mean(lux,na.rm=T),Turbidity_1hour_mean=mean(Turbidity,na.rm=T))
dblong_hour<-merge(dblong_hour,env_10min_to_1hour,by="Date_time",all.x = T)
rm(env_10min_to_1hour)
write.csv(dblong_hour, "Big_Hobo_databse_long_hour_percent&env.csv")
```

##Env_daily
```{r}
env_1day <- dblong10 %>% 
  select(Temp,lux,Turbidity,group) %>% 
  distinct()
env_1day$group <- parse_date_time(env_1day$group,orders = "ymd HMS")
env_1day$Date_time <- cut(env_1day$group, breaks= "1 day")
env_1day$Temp <- as.numeric(env_1day$Temp)
env_1day$lux <- as.numeric(env_1day$lux)
env_1day$Turbidity <- as.numeric(env_1day$Turbidity)
env_1day <-env_1day %>%
  group_by(Date_time) %>%
  summarise(Temp_1day_mean=mean(Temp,na.rm=T),Lux_1day_mean=mean(lux,na.rm=T),Turbidity_1day_mean=mean(Turbidity,na.rm=T))
temp_env_1hour <- dblong_hour %>% 
  select(Date_time,`Hs[m]`) %>% 
  distinct()
temp_env_1hour$Date_time <- parse_date_time(temp_env_1hour$Date_time,orders = "ymd HMS")
temp_env_1hour$Date_time <- cut(temp_env_1hour$Date_time, breaks= "1 day")
temp_env_1hour$`Hs[m]` <- as.numeric(temp_env_1hour$`Hs[m]`)
temp_env_1hour <-temp_env_1hour %>%
  group_by(Date_time) %>%
  summarise(Hs_1day_mean=mean(`Hs[m]`,na.rm=T))
env_1day <- merge(env_1day,temp_env_1hour,by="Date_time")
rm(temp_env_1hour)
```

##Env_1week - reco
```{r}
reco<-read.csv("RECO_Database - Data.csv")
reco$mm.dd.yyyy<-parse_date_time(reco$mm.dd.yyyy,orders = "mdy",truncated = 3)
#divide into chucks of weeks
reco$group <- cut(reco$mm.dd.yyyy, breaks="week")
#filter to only shallow station 
reco <- reco %>%filter(Station=="ST3") %>%
  select(group,Cal.Chl...ug.L.,Depth..m.) %>% 
  group_by(group)
#summarise to all depths
reco <- reco %>% 
  summarise(Chl=mean(Cal.Chl...ug.L.,na.rm=T)) %>% 
  arrange(group)
#make sure the group columns are the same
reco$group <- as.POSIXct(reco$group,format = "%Y-%m-%d")
dblong_week$group <- as.POSIXct(dblong_week$group,format = "%Y-%m-%d")
dblong_week <- merge(dblong_week,reco,by="group",all.x = T)

```

##2min sunrise.set and Day/Night calculations
```{r}
##Sunrise.set calculations

#sampling point coordinates
rei_point_crds <- c(32.4015190,34.8579670)
dblong2$group<- parse_date_time(dblong2$group,orders = "ymd HMS")
#creating column represent only the sampling dates
dblong2$Date <- as.Date(dblong2$group)
sampling_dates <- unique(dblong2$Date)
#create a data frame for sunrise.set for all the sampling dates
temp_date <- data.frame(matrix(NA,ncol=3,nrow=length(sampling_dates)))
names(temp_date) <- c("Date","Sunrise","Sunset")
temp_date$Date <- sampling_dates
rm(sampling_dates)
#calculate sunrise.set
for (day in 1:length(temp_date$Date)) {
  sunrise_set <- sunrise.set(rei_point_crds[1],rei_point_crds[2], as.Date(temp_date$Date[day]),timezone = "Asia/Jerusalem")
  temp_date$Sunrise[day] <- as.POSIXct(sunrise_set$sunrise)
  temp_date$Sunset[day] <- as.POSIXct(sunrise_set$sunset)
}
#change from numeric to datetime
temp_date$Sunrise <- as.POSIXct(as.numeric(temp_date$Sunrise),origin='1970-01-01')
temp_date$Sunset <- as.POSIXct(as.numeric(temp_date$Sunset),origin='1970-01-01')
temp_date$Sunrise <- force_tz(temp_date$Sunrise,tzone = "UTC") 
temp_date$Sunset <- force_tz(temp_date$Sunset,tzone = "UTC") 

dblong2<-merge(dblong2,temp_date,by="Date",all.x = T)
dblong2$Date <- NULL
rm(temp_date)


##Day.Night Calculations
dblong2$Day_Night <- ifelse(dblong2$group>dblong2$Sunrise & dblong2$group<dblong2$Sunset,"Day","Night")
#create new data frame composing only from distinct date times
temp_sun <- dblong2 %>% select(group,Sunrise,Sunset,Day_Night,Deployment.number) %>% distinct()
#calculate time difference from sunset for the day times
temp_sun$diff_sunset[temp_sun$Day_Night=="Day"] <- difftime(temp_sun$group[temp_sun$Day_Night=="Day"],temp_sun$Sunset[temp_sun$Day_Night=="Day"],units = "hours")
#calculate time difference for night times, complicated because the change of the dates at midnight
temp_night <- temp_sun[temp_sun$Day_Night=="Night",]
temp_night <- temp_night %>% arrange(group)
#calculate for times before midnight
temp_night$diff_sunset[as.numeric(format(temp_night$group,"%H"))>10] <-difftime(temp_night$group[ as.numeric(format(temp_night$group,"%H"))>10],temp_night$Sunset[as.numeric(format(temp_night$group ,"%H"))>10],units = "hours")

#calculate time difference for night times after midnight
dep_num <- 0
for (row_num in 1:dim(temp_night)[1]) {
  if (!is.na(temp_night$diff_sunset[row_num])) {
    #save the sunset time of the date before midnight
    temp_sunset <- temp_night$Sunset[row_num]
    #save the deployment number to avoid deployments mixing
    dep_num <- temp_night$Deployment.number[row_num]
  } else if (is.na(temp_night$diff_sunset[row_num]) & temp_night$Deployment.number[row_num]==dep_num) {
    temp_night$diff_sunset[row_num] <- difftime(temp_night$group[row_num],temp_sunset)
  }
}
#merging all the  data frames together
temp_night <- temp_night %>% select(group,diff_sunset)
#merging two partly full columns into one
temp_sun <- temp_sun %>% left_join(y,by="group") %>%
  mutate(diff_sunset = ifelse(is.na(diff_sunset.x),diff_sunset.y,diff_sunset.x)) %>% 
  select(-diff_sunset.x,-diff_sunset.y)
temp_sun <- temp_sun %>% select(group,diff_sunset) %>% arrange(group)
dblong2 <- merge(dblong2,temp_sun,by = "group",all.x = T)
rm(temp_sun)
rm(temp_night)
saveRDS(dblong2,"Big_Hobo_database_long_2min_percent&sun.RDS")
```


##Bivalves correlations - per deployment
```{r}
#Bivalves correlations - correlation between each bivalve pair in a singe deployment
dbwide2 <- dblong2 %>% select(group,Deployment.number,Biv_num,biv_open_interval_perc) %>% 
  spread(key = Biv_num,value = biv_open_interval_perc)
write.csv(dbwide2,"Big_Hobo_database_wide_2min_percent.csv")
deployments <- unique(dbwide2$Deployment.number)
bivalve_corr <- data.frame(dep_num=integer(),
                           corr_values=double(),
                           p_values=double(),
                           n=integer()
)
for (dep in deployments) {
temp_dep <- dbwide2 %>% filter(Deployment.number==dep)
#remove bivalves weren't deployed in the specific deployment
temp_dep <- temp_dep[,colSums(!is.na(temp_dep))>0]
# remove datetime and deployment number
temp_dep <- temp_dep[-1:-2]
#getting correlation, p-values and n and convert them to data frame
temp_corr <- rcorr(as.matrix(temp_dep),type = "pearson")
temp_corr <-data.frame(dep_num = paste("Deployment",dep),
                       corr_values = as.vector(temp_corr[["r"]][upper.tri(temp_corr[["r"]])]),
                       p_values = as.vector(temp_corr[["P"]][upper.tri(temp_corr[["P"]])]),
                       n = as.vector(temp_corr[["n"]][upper.tri(temp_corr[["n"]])])
                       )
bivalve_corr <- rbind(bivalve_corr,temp_corr)                       
}
rm(temp_corr,temp_dep)
write.csv(bivalve_corr,"Bivalves_correlations.csv")
hist(biv_corr_hour$corr_values[biv_corr_hour$p_values<0.05],breaks = seq(-1,1,0.1))
```



##Environmental correlations - per deployment/whole duration/daily_all_bivalves
```{r}
#Environmental correlations - hourly include deployments
#wide bivalves
dbwide_hour <- dblong_hour %>% select(Date_time,Deployment.number,Bivalve.number,mean.biv.gap.precent) %>%
  spread(key = Bivalve.number,value = mean.biv.gap.precent)
#wide environment
environment_wide <- dblong_hour %>% select(Date_time,Deployment.number,`Hs[m]`,`Tp[s]`,`Dp[deg]`,`H1/10[m]`,`Tmean[s]`,`Current.Speed[cm/sec]`,`Current.Direction[deg]`,Temp_1hour_mean,Lux_1hour_mean,Turbidity_1hour_mean) %>% 
  distinct()
#get all the deployments
deployments <- unique(dbwide_hour$Deployment.number)
#prepare the big data frame
env_corr <- data.frame(dep_num=integer(),
                       biv_num=character(),
                       environmental_factor=character(),
                       corr_values=double(),
                       p_values=double(),
                       n=integer()
)

for (dep in deployments) {
temp_dep <- dbwide_hour %>% filter(Deployment.number==dep)
#remove bivalves weren't deployed in the specific deployment
temp_dep <- temp_dep[,colSums(!is.na(temp_dep))>0]
# get the bivalves names
temp_bivalves_id <- names(temp_dep)[3:dim(temp_dep)[2]]
#filter environmental data to a specific deployment
temp_env <- environment_wide %>% filter(Deployment.number==dep)
temp_env <- temp_env %>% select(-Deployment.number)
for (biv_num in temp_bivalves_id) {
  temp_biv <- temp_dep[,c(1,which(colnames(temp_dep)==biv_num ))]
  temp_biv <- merge(temp_biv,temp_env,by="Date_time",all.x=T)
  #remove datetime
  temp_biv <- temp_biv %>% select(-Date_time)
  #getting correlation, p-values and n and convert them to data frame
  temp_corr <- rcorr(as.matrix(temp_biv),type = "pearson")
  temp_corr <-data.frame(dep_num = paste("Deployment",dep),
                       biv_num=biv_num,
                       #starting from 2 to avoid autocorrelation with the bivalve
                       #getting the environmental factors names
                       environmental_factor=colnames(temp_corr[["r"]])[2:length(colnames(temp_corr[["r"]])
                                                                                )],
                       corr_values = as.vector(temp_corr[["r"]][1,2:dim(temp_corr[["r"]])[2]]),
                       p_values = as.vector(temp_corr[["P"]][1,2:dim(temp_corr[["P"]])[2]]),
                       n = as.vector(temp_corr[["n"]][1,2:dim(temp_corr[["n"]])[2]])
                       )
env_corr <- rbind(env_corr,temp_corr)
  }
}
rm(temp_corr,temp_dep,temp_env,temp_biv)
write.csv(env_corr,"Environmental_correlations_hour_by_Deployment")
hist(env_corr$corr_values[env_corr$environmental_factor=="Temp_1hour_mean" & env_corr$p_values<0.05],breaks = seq(-1,1,0.1))




#Environmental correlations - hourly, all duration
#wide bivalves
dbwide_hour <- dblong_hour %>% select(Date_time,Deployment.number,Bivalve.number,mean.biv.gap.precent) %>%
  spread(key = Bivalve.number,value = mean.biv.gap.precent)
#wide environment
environment_wide <- dblong_hour %>% select(Date_time,Deployment.number,`Hs[m]`,`Tp[s]`,`Dp[deg]`,`H1/10[m]`,`Tmean[s]`,`Current.Speed[cm/sec]`,`Current.Direction[deg]`,Temp_1hour_mean,Lux_1hour_mean,Turbidity_1hour_mean) %>% 
  distinct()
#prepare the big data frame
env_corr <- data.frame(biv_num=character(),
                       environmental_factor=character(),
                       corr_values=double(),
                       p_values=double(),
                       n=integer()
)

#get the bivalves names
bivalves_id <- unique(dblong_hour$Bivalve.number)
for (biv_num in bivalves_id) {
  temp_biv <- dbwide_hour[,c(1,which(colnames(dbwide_hour)==biv_num ))]
  temp_biv <- merge(temp_biv,environment_wide,by="Date_time",all.x=T)
  #remove datetime
  temp_biv <- temp_biv %>% select(-Deployment.number,-Date_time)
  #getting correlation, p-values and n and convert them to data frame
  temp_corr <- rcorr(as.matrix(temp_biv),type = "pearson")
  temp_corr <-data.frame(biv_num=biv_num,
                       #starting from 2 to avoid autocorrelation with the bivalve
                       #getting the environmental factors names 
                       environmental_factor=colnames(temp_corr[["r"]])[2:length(colnames(temp_corr[["r"]])
                                                                                )],
                       corr_values = as.vector(temp_corr[["r"]][1,2:dim(temp_corr[["r"]])[2]]),
                       p_values = as.vector(temp_corr[["P"]][1,2:dim(temp_corr[["P"]])[2]]),
                       n = as.vector(temp_corr[["n"]][1,2:dim(temp_corr[["n"]])[2]])
                       )
  env_corr <- rbind(env_corr,temp_corr)
}
rm(temp_corr,temp_biv)
hist(env_corr$corr_values[env_corr$environmental_factor=="Temp_1hour_mean" & env_corr$p_values<0.05],breaks = seq(-1,1,0.1))
write.csv(env_corr,"Environmental_correlations_hour_all_duration.csv")





##Environmental correlations - weekly (chl) 
#wide bivalves
dbwide_week <- dblong_week %>% select(group,Deployment.number,Biv_num,biv_open_interval_perc) %>%
  spread(key = Biv_num,value = biv_open_interval_perc)
#prepare the big data frame
env_corr_week <- data.frame(biv_num=character(),
                       environmental_factor=character(),
                       corr_values=double(),
                       p_values = double(),
                       alues=double(),
                       n=integer()
)
for (biv_num in bivalves_id) {
    temp_biv <- dbwide_week[,c(1,which(colnames(dbwide_hour)==biv_num ))]
    temp_biv <- merge(temp_biv,reco,by="group",all.x=T)
    temp_biv <- temp_biv %>% select(-group)
    #getting correlation, p-values and n and convert them to data frame
    temp_corr <- rcorr(as.matrix(temp_biv),type = "pearson")
    temp_corr <-data.frame(biv_num=biv_num,
                       #starting from 2 to avoid autocorrelation with the bivalve
                       #getting the environmental factors names
                       environmental_factor="Chl",
                       corr_values = as.vector(temp_corr[["r"]][1,2:dim(temp_corr[["r"]])[2]]),
                       p_values = as.vector(temp_corr[["P"]][1,2:dim(temp_corr[["P"]])[2]]),
                       n = as.vector(temp_corr[["n"]][1,2:dim(temp_corr[["n"]])[2]])
                       )
    env_corr_week <- rbind(env_corr_week,temp_corr)
}
rm(temp_corr)
write.csv(env_corr_week,"Chl_correlations_week-all_duration.csv")
env_corr_week_significant <- env_corr_week %>% filter(p_values<0.05)
hist(env_corr_week$corr_values,seq(-1,1,by=0.1))



###Environmental correlations - daily for mean of all bivalves
#get mean open percentage daily to all bivalves
open_perc_daily <-dblong_day %>%
  group_by(group) %>%
  summarise(daily_mean_open_perc=mean(biv_open_interval_perc),daily_mean_biv_open_degree=mean(biv_open_interval),n_bivalves=n())
#get mean open time ratio daily to all bivalves
open_time_daily <- bivalves_daily_open %>% 
  filter(limit==20) %>% 
  group_by(date) %>%
  summarise(daily_mean_open_time_ratio=mean(open_time_ratio))
#make them in same format and merge
names(open_time_daily)[1] <- "group"
open_perc_daily$group <- as.Date(open_perc_daily$group)
biv_mean_daily <- merge(open_perc_daily,open_time_daily,by="group")

#merge the environmental data
names(env_1day)[1] <- "group"
env_1day$group <- as.Date(env_1day$group)
biv_mean_daily <- merge(biv_mean_daily,env_1day)

#remove unnecessery columns
temp_corr <- biv_mean_daily %>% select(-group,-n_bivalves,-daily_mean_biv_open_degree)
#prepare the correlation data frame and calculate it
temp_corr <- rcorr(as.matrix(temp_corr),type = "pearson")
env_corr_day <- data.frame(matrix(NA,nrow=8,ncol=5))
names(env_corr_day) <- c("biv_factor","environmental_factor","corr_values","p_values","n")
env_corr_day$biv_factor <- c(rep("open_time",4),rep("open_perc",4))
env_corr_day$environmental_factor <- rep(c("Temp","Light","Turbidity","Hs"),2)
env_corr_day$corr_values[1:4] <- temp_corr[["r"]][2,3:6]
env_corr_day$p_values[1:4] <- temp_corr[["P"]][2,3:6]
env_corr_day$n[1:4] <- temp_corr[["n"]][2,3:6]
env_corr_day$corr_values[5:8] <- temp_corr[["r"]][1,3:6]
env_corr_day$p_values[5:8] <- temp_corr[["P"]][1,3:6]
env_corr_day$n[5:8] <- temp_corr[["n"]][1,3:6]
rm(temp_corr)
write.csv(env_corr_day,"Environmental_correlations_day_all_bivalves.csv")

```
##Bivalve opening times(how much time was open in whole duration/daily/3h)
```{r}
###check mean and max opening time for each bivalve for the whole deployments duration
bivalves_names<-unique(dblong2$Biv_num)
#prepare the data frame
bivalves_opening_times<-data.frame(
  bivalve_name=character(),
  mean.opening.time=double(),
  max.opening.time=double(),
  n=double(),
  sd=double(),
  se=double(),
  limit=double()
)
#Check different limits defined as closed
precent_limits<-c(1,5,10,15,20,30)
#loop for all limits
#index for which precent limit iteration are we in
limit_iter_num <- 0 
for (limit in precent_limits) {
  #loop for all bivalves
  for (biv_num in 1:length(bivalves_names)) {
    #filter by bivalve
    temp_biv<-filter(dblong2,dblong2$Biv_num==bivalves_names[biv_num])
    open_events<-c()
    bivalves_opening_times[biv_num+limit_iter_num,]<-NA
    bivalves_opening_times$bivalve_name[biv_num+limit_iter_num]<-bivalves_names[biv_num]
    bivalves_opening_times$limit[biv_num+limit_iter_num]<-limit
    open_index<-1
    total_time<-0#for computing  total time of measurement per bivalve
    sum_time_open<-0
    #loop for each bivalve
    for (row in 1:dim(temp_biv)[1]) {
      total_time<-total_time+2
      #check if the bivalve closed or if we passed deployment or passed day
      if(temp_biv$biv_open_interval_perc[row]<limit || (row!=1 && temp_biv$Deployment.number[row]!=temp_biv$Deployment.number[row-1]))
      {
        #check if it was open before
        if(sum_time_open>0)
        {
          #initializing the next open event
          open_events[open_index]<-NA
          #add the opening time to the series of all the gaping events
          open_events[open_index]<-sum_time_open
          #increase the number of gaping events
          open_index<-open_index+1
        }
        #zeroing the counter of the time the bivalve is open 
        sum_time_open<-0
      } 
      else
      {
        #increase the time of gaping by 2 because each row represent 2 minutes
        sum_time_open<-sum_time_open+2
      }
    } 
    #maximum time open continously during 1 deployment
    bivalves_opening_times$max.opening.time[biv_num+limit_iter_num]<-max(open_events)
    #mean time open continuosly during 1 deployment
    bivalves_opening_times$mean.opening.time[biv_num+limit_iter_num]<-mean(open_events) 
    #amount of distinct opening events
    bivalves_opening_times$n[biv_num+limit_iter_num]<-length(open_events)
    bivalves_opening_times$sd[biv_num+limit_iter_num]<-sd(open_events)
    bivalves_opening_times$se[biv_num+limit_iter_num]<-bivalves_opening_times$sd[biv_num+limit_iter_num]/sqrt(bivalves_opening_times$n[biv_num+limit_iter_num])
    #precent of time open in compare to the whole deployment duration of the bivalve
    bivalves_opening_times$total_time_open[biv_num+limit_iter_num]<-sum(open_events)/total_time*100
    #for computing total time open percetange for each bivalve
  }
  limit_iter_num<-limit_iter_num+12
}
write.csv(bivalves_opening_times,"Bivalves_open_all_duration.csv")
opening_interval_sum<- bivalves_opening_times %>% 
  group_by(limit)%>%
 summarise(biv_open_interval_mean=mean(mean.opening.time),sd_opening_time=sd(mean.opening.time),n=n(),biv_total_open_perc=mean(total_time_open),sd.total_time_open=sd(total_time_open))%>%


  
  
##check mean and max opening time for each bivalve for the each day
bivalves_daily_open <- data.frame(
  bivalve_name=character(),
  date=Date(),
  open_time_ratio=double(),
  n=integer(),
  limit=integer()
)
#loop for all bivalve
limit_iter_num<-0 #index for precent limits
for (limit in precent_limits) {
  for (biv_num in 1:length(bivalves_names)) {
    #filter by bivalve
    temp_biv<-dplyr::filter(dblong2,dblong2$Biv_num==bivalves_names[biv_num])
    temp_biv$date<-as.Date(temp_biv$group)
    dates<-unique(temp_biv$date)
    open_times<-c(NA,length(dates))
    #how much time of the day was covered
    data_in_day <- c(NA,length(dates))
    #loop for all dates
    for (date_num in 1:length(dates)) {
      temp_date<-temp_biv %>% filter(date==dates[date_num])
      temp_date_open <- temp_date %>% filter(biv_open_interval_perc>limit)
      open_times[date_num]<-dim(temp_date_open)[1]/dim(temp_date)[1]
      data_in_day[date_num] <- dim(temp_date)[1]
    }
    temp_daily_open <- data.frame(
      bivalve_name=bivalves_names[biv_num],
      date=dates,
      open_time_ratio=open_times,
      n=data_in_day,
      limit=limit
    )
    bivalves_daily_open <- rbind(bivalves_daily_open,temp_daily_open)
  }
  limit_iter_num<-limit_iter_num+12
  write.csv(bivalves_daily_open,"Bivalves_daily_open_time_ratio.csv")
}


```

## Seasonal & Daily trend Plot

```{r}
#seasonal and daily trend along bivalves - Work!
dblong2$group <- parse_date_time(dblong2$group,orders = "ymd HMS")
dblong2$Month <- format(dblong2$group,"%Y-%m")
dblong2$TimeofDay <- as.POSIXct(hms::as_hms(dblong2$group)) 
months_gaping_graph <- ggplot(dblong2, aes(x = TimeofDay, y = biv_open_interval_perc))+
  geom_point(color = "grey", size = 0.1)+
  geom_smooth(linewidth = 2, color = "blue",se = T,fill="red")+
  # geom_spline(spar = 0.05, linewidth = 2, color = "blue")+
  scale_x_datetime( date_breaks = "4 hours",date_labels = "%H:%M") +
  scale_y_continuous(limits = c(0,100))+
  facet_wrap(~Month, scales = "free_x", ncol = length(unique(dblong2$Month))) +
  labs(x = "Time of Day",
       y = "Gaping Percent") +
  theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"),
        strip.background = element_rect(fill="white",color="black", linewidth = 1.5, linetype="solid"),
        axis.title.y = element_text(size = 20),
        axis.title.x = element_blank(),
        axis.text.y = element_text(size = 14),
        axis.text.x = element_text(size = 14, angle = 45, hjust = 1),
        strip.text = element_text(size = 14),
        legend.text = element_text(size = 14))
  months_gaping_graph
  
```

##Day_night plot
```{r}
#Day Night difference -  Work only for 0 to 100 range!
  Day_Night_gaping_graph <- ggplot(dblong2, aes(x = diff_sunset, y = biv_open_interval_perc)) +
    geom_point(size = 0.1, alpha = 0.5, color = "gray") +
    geom_smooth(data = subset(dblong2,diff_sunset>0), size = 1.5,color = "blue", se =T,fill="yellow")+ 
    geom_smooth(data = subset(dblong2,diff_sunset<0), size = 1.5,color = "red",se =T,fill="yellow")+
    geom_vline(xintercept = 0,linetype="dashed",color="black")+
    scale_y_continuous(limits = c(0,100))+
    scale_x_continuous(limits = c(-12,12),breaks = seq(-12,12,2))+
    labs(title = "Bivalve Open Interval Percentage Over Time",
         x = "Time",
         y = "Bivalve Open Percentage") 
Day_Night_gaping_graph

```

##Correlations plot - bivalves and environmental
```{r}

#Bivalve correlation graph - without mean!
correlation_hitsogram <- ggplot(bivalve_corr, aes(corr_values)) +
                           geom_histogram(binwidth = 0.1,breaks = seq(-1, 1, by = 0.1), 
                                          fill = "antiquewhite1", color = "black") +
                           scale_x_continuous(limits = c(-1,1),breaks =seq(-1, 1, by = 
                                            0.2),minor_breaks = seq(-1, 1, by = 0.1))+
                           labs(x = "Correlation values",y = "Count")+
                           geom_vline(xintercept = 0, linetype = "dashed", color = "red", 
                                      size = 1)+
                           theme_bw()+
                           theme(title=element_blank(),
                           panel.grid.major = element_blank(),
                           panel.grid.minor = element_blank(),
                           panel.background = element_blank(),
                           panel.border = element_blank(),
                           axis.line.y = element_line(colour = "black"),
                           axis.line.x = element_line(colour = "black"))
                           
 
correlation_boxplot <- ggplot(bivalve_corr, mapping =  
                       aes(corr_values))+geom_boxplot(aes(y=corr_values,x=NULL),fill = 
                                                        "antiquewhite1", color = "black")+
                       scale_y_continuous(limits = c(-1,1),breaks =seq(-1, 1, by = 
                                          0.2),minor_breaks = seq(-1, 1, by = 0.1) )+
                       geom_hline(yintercept = 0, linetype = "dashed", color = "red", 
                                      size = 1)+
                       coord_flip()+
                       theme_bw()+
                       theme_void()+
                       theme(panel.grid.major = element_blank(),
                       panel.grid.minor = element_blank(),
                       panel.background = element_blank(),
                       axis.ticks.y = element_blank(),
                       axis.title.y = element_blank(),
                       axis.text.y = element_blank())
biv_corr_plot <- correlation_boxplot/correlation_hitsogram+
             plot_layout(heights = c(0.2,4))+
             plot_annotation(title = 'Bivalves Correlations')


#Environmental correlation graph - Without mean!
env_corr_plot_data <- env_corr %>% filter(environmental_factor %in% c("Hs.m.","Temp_1hour_mean","Lux_1hour_mean","Turbidity_1hour_mean"))
env_factors <- unique(env_corr_plot_data$environmental_factor)
env_colors <- c("cornflowerblue","coral2","gold","chocolate4")
env_corr_plots <- list()
for (factor_num in 1:length(env_factors)) {
  temp_env_factor <- env_corr_plot_data %>% 
    filter(environmental_factor == env_factors[factor_num])
  env_correlation_hitsogram <- ggplot(temp_env_factor, aes(corr_values)) +
                           geom_histogram(binwidth = 0.1,breaks = seq(-1, 1, by = 0.1), 
                                          fill = env_colors[factor_num], color = "black") +
                           scale_x_continuous(limits = c(-1,1),breaks =seq(-1, 1, by = 
                                            0.2),minor_breaks = seq(-1, 1, by = 0.1))+
                           labs(x = "Correlation values",y = "Count")+
                           geom_vline(xintercept = 0, linetype = "dashed", color = "red", 
                                      size = 1)+
                           theme_bw()+
                           theme(title=element_blank(),
                           panel.grid.major = element_blank(),
                           panel.grid.minor = element_blank(),
                           panel.background = element_blank(),
                           panel.border = element_blank(),
                           axis.line.y = element_line(colour = "black"),
                           axis.line.x = element_line(colour = "black"))
                           
 
  env_correlation_boxplot <- ggplot(temp_env_factor, mapping =  
                       aes(corr_values))+geom_boxplot(aes(y=corr_values,x=NULL),fill = 
                                                        env_colors[factor_num], color =
                                                        "black")+
                       scale_y_continuous(limits = c(-1,1),breaks =seq(-1, 1, by = 
                                          0.2),minor_breaks = seq(-1, 1, by = 0.1) )+
                       geom_hline(yintercept = 0, linetype = "dashed", color = "red", 
                                      size = 1)+
                       coord_flip()+
                       theme_bw()+
                       theme_void()+
                       theme(panel.grid.major = element_blank(),
                       panel.grid.minor = element_blank(),
                       panel.background = element_blank(),
                       axis.ticks.y = element_blank(),
                       axis.title.y = element_blank(),
                       axis.text.y = element_blank())
  
  env_corr_plots[[factor_num]] <- env_correlation_boxplot/env_correlation_hitsogram+
             plot_layout(heights = c(0.2,4))+
             plot_annotation(title = paste(env_factors[factor_num],"correlations"))

}

##All corr plot combined together
corr_plot <- ggarrange(biv_corr_plot,env_corr_plots[[1]],env_corr_plots[[2]],env_corr_plots[[3]],env_corr_plots[[4]],nrow = 5)
```


##Opening times violin plot
```{r}
bivalves_opening_times$limit <- as.factor(bivalves_opening_times$limit )
opening_violin_plot <- ggplot(bivalves_opening_times,aes(x=limit,y=mean.opening.time)
                              )+
                       geom_violin(aes(fill=limit))+
                       geom_boxplot(width=0.1, color="black",fill="white") +
                       labs(x = "Close definition percentage [%]", y = "Mean opening interval [min]")+
                       scale_y_continuous(breaks = seq(0,120,by=10))+
                       theme_bw()+
                       theme(panel.grid.major = element_blank(),
                       panel.grid.minor = element_blank(),
                       panel.background = element_blank(),
                       legend.position="none")
```

